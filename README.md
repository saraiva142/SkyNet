<h1 align="center">SKYNET - IIV DESAFIO DE CIEÃÇNCIA DE DADOS ü§ñ </h1>

## Equipe:
![image](https://github.com/user-attachments/assets/82ff4621-877c-4b38-aede-2cdea8b95dc0)

## Projeto:

### Sobre o desafio:

"O vento solar interagindo com a magnetosfera da Terra pode causar tempestades geomagn√©ticas, danificando tecnologias cr√≠ticas. O √≠ndice de perturba√ß√£o-tempestade-tempo (Dst) mede a gravidade da tempestade, impulsionando modelos de perturba√ß√£o geomagn√©tica. A previs√£o tradicional de Dst depende de observa√ß√µes do vento solar, mas modelos recentes de Aprendizado de M√°quina (ML) mostram-se promissores". Para explorar solu√ß√µes vi√°veis de ML, a Pontif√≠cia Universidade Cat√≥lica de Goi√°s organizou o VII Desafio de Ci√™ncia de Dados. Com o objetivo de modelos baseados em ML para prever Dst sejam criados e estudados. O documento resume os resultados e insights do problema proposto, enfatizando o potencial do ML para aprimorar a previs√£o de tempestades geomagn√©ticas para aplica√ß√µes pr√°ticas.

### Motivo do desafio:

O desafio busca promover o trabalho em equipe, an√°lise explorat√≥ria de dados, filtragem de dados, modelagem e algoritmos, aprendizado de linguagens de programa√ß√£o, machine learning e racioc√≠nio l√≥gico, com o objetivo de analisar os dados e fazer predi√ß√µes com s√©ries temporais.

O escopo deste projeto envolve a cria√ß√£o de modelos de predi√ß√£o de tempestades geomagn√©ticas. Especificamente, o projeto visa:

1. **An√°lise Inicial dos Dados:** Descrever e explorar os dados brutos, identificar caracter√≠sticas importantes, e preparar os dados para o treinamento dos modelos.

2. **Pr√©-processamento de Dados:** Realizar a limpeza e pr√©-processamento dos dados, incluindo o tratamento de valores ausentes, a codifica√ß√£o de vari√°veis categ√≥ricas e a normaliza√ß√£o, quando necess√°rio.

3. **Desenvolvimento dos Modelos de Predi√ß√£o:** Selecionar e desenvolver um modelo de previs√£o apropriado para estimar DST, tendo em vista as 3 fases de uma tempestade geomagn√©tica. Isso pode envolver o uso de t√©cnicas de aprendizado de m√°quina, como regress√£o, s√©ries temporais ou algoritmos de an√°lise de texto, dependendo da natureza dos dados.

4. **An√°lise de Resultados:** Comparar o desempenho dos modelos e entender seus pontos fortes e fracos.

5. **Conclus√µes**: Resumir os principais achados e pr√≥ximos passos.

### Dados:

[![Static Badge](https://img.shields.io/badge/Dados%20brutos-Link-green?style=for-the-badge&logo=googlesheets)](https://drive.google.com/drive/folders/1S0WJQPltZ0j27zHfx-g2k7t6WiYeO8L-?usp=sharing)
[![Static Badge](https://img.shields.io/badge/Dados%20pre_processados-Link-green?style=for-the-badge&logo=googlesheets)](https://drive.google.com/drive/folders/1ug2s2DzdGoITI37N39TgTQlN0rowE6Uk?usp=drive_link)
[![Static Badge](https://img.shields.io/badge/Dicion√°rio%20de%20Dados%20-%20PDF%20-%20red?style=for-the-badge&logo=files&logoColor=red
)](https://github.com/saraiva142/SkyNet/blob/main/dicion%C3%A1rio%20de%20dados%20-%20VII%20desafio%20CD%202024.pdf)  

### Codigo:
#ARRUMAR LINKS:
[![Static Badge](https://img.shields.io/badge/C%C3%B3digo%20do%20RNN-Link-orange?style=for-the-badge&logo=googlecolab)
](https://colab.research.google.com/drive/1uLOrRYRu0naYLgmg8IZW7uiGS4rvxcmh?usp=sharing)
[![Static Badge](https://img.shields.io/badge/C%C3%B3digo%20do%20Transformer-Link-orange?style=for-the-badge&logo=googlecolab)
](https://colab.research.google.com/drive/1uLOrRYRu0naYLgmg8IZW7uiGS4rvxcmh?usp=sharing)
[![Static Badge](https://img.shields.io/badge/todos%20os%20modelos%20usados-Link-blue?style=for-the-badge)
](https://github.com/saraiva142/SkyNet/tree/main)

# 1 - **An√°lise Inicial dos Dados**

A an√°lise inicial de dados √© uma etapa onde buscamos compreender a estrutura dos dados e identificar quais vari√°veis t√™m maior impacto nas respostas que estamos tentando modelar. No nosso caso, o objetivo √© entender como diferentes vari√°veis afetam o √≠ndice Dst, que est√° relacionado a tempestades geomagn√©ticas, e, a partir disso, descobrir os dados mais importantes para alimentar nossos modelos preditivos.

### 1.1 - Visualiza√ß√£o e Estat√≠sticas Descritivas

A seguir, foram geradas visualiza√ß√µes iniciais e estat√≠sticas descritivas para obter uma vis√£o geral da distribui√ß√£o dos dados. A inspe√ß√£o visual dos dados e o c√°lculo de estat√≠sticas b√°sicas como m√©dia, desvio padr√£o, valores m√≠nimos e m√°ximos tamb√©m nos ajudaram a identificar poss√≠veis padr√µes e anomalias nos dados, como varia√ß√µes inesperadas em determinadas vari√°veis que poderiam prejudicar a performance do modelo.

![image](https://github.com/user-attachments/assets/40d95a79-d2c7-4bc3-a3cf-405f8bf6a3e3)

![image](https://github.com/user-attachments/assets/d3ba8495-f717-42bb-8f7c-a6bc2dbf4e88)

A an√°lise da distribui√ß√£o do √≠ndice Dst, que √© a vari√°vel alvo, revelou a concentra√ß√£o de valores em determinadas faixas e indicou a presen√ßa de outliers (eventos extremos). Esses outliers podem ser eventos extremos importantes para a modelagem de tempestades geomagn√©ticas.

![image](https://github.com/user-attachments/assets/a0d8ac24-2237-4d99-a7a2-1945dabbd381)

### 1.2 - An√°lise de Correla√ß√£o

Uma das principais ferramentas na an√°lise de dados √© a correla√ß√£o, que nos permite medir a for√ßa e a dire√ß√£o das rela√ß√µes entre as vari√°veis. Para isso, foi criada uma matriz de correla√ß√£o para as colunas num√©ricas do conjunto de dados de vento solar (solar_wind.csv). Essa matriz √© uma pe√ßa fundamental para identificar quais vari√°veis podem ser mais relevantes para a predi√ß√£o do √≠ndice Dst.

Al√©m disso, foi feita uma an√°lise espec√≠fica da correla√ß√£o entre as vari√°veis de vento solar e o √≠ndice Dst. Ao combinar as vari√°veis do vento solar com as informa√ß√µes do √≠ndice Dst, conseguimos ver diretamente quais delas t√™m uma rela√ß√£o mais forte com o Dst. Isso nos ajudar√° a focar nas features que mais impactam o fen√¥meno que estamos estudando ‚Äî tempestades geomagn√©ticas.

![image](https://github.com/user-attachments/assets/98f28711-63b7-4e73-8888-4e4df6e26349)

Valores pr√≥ximos de 1 ou -1 indicam uma correla√ß√£o forte, onde 1 sugere uma rela√ß√£o positiva direta e -1 uma rela√ß√£o inversa. Ao identificar as vari√°veis cujos coeficientes de correla√ß√£o com o Dst se aproximam de 1 ou -1, podemos determinar quais fatores do vento solar ou posi√ß√£o dos sat√©lites t√™m maior influ√™ncia sobre as tempestades geomagn√©ticas. Essas vari√°veis s√£o consideradas as mais importantes para o nosso modelo de previs√£o, j√° que sua rela√ß√£o mais forte com o Dst sugere que podem ser preditores chave para a modelagem.

Para ilustrar melhor essas correla√ß√µes, geramos o gr√°fico Correla√ß√£o das vari√°veis com o √≠ndice Dst, que apresenta visualmente a for√ßa e o sentido da correla√ß√£o de cada vari√°vel. Isso nos permite priorizar vari√°veis com maiores pesos na constru√ß√£o do modelo de predi√ß√£o, focando naquelas que t√™m impacto mais significativo sobre o √≠ndice Dst.

![image](https://github.com/user-attachments/assets/e0e36d92-05f2-4368-80a5-e6519f4626ca)


# 2. **Pr√©-processamento de Dados**

No processo de modelagem, o pr√©-processamento dos dados √© uma etapa fundamental para garantir que o modelo receba entradas limpas e bem estruturadas. Ele envolve v√°rias tarefas, como a limpeza de dados inconsistentes ou ausentes, a codifica√ß√£o de vari√°veis categ√≥ricas para permitir que modelos num√©ricos as interpretem, e a normaliza√ß√£o das vari√°veis num√©ricas, ajustando-as para uma escala comum. Esse tratamento cuidadoso √© crucial para melhorar a qualidade dos dados, reduzir vi√©s e garantir que o modelo capture padr√µes relevantes de maneira eficaz.



#ESPERANDO RETORNO DA LUD



# 3. **Desenvolvimento dos Modelos de Predi√ß√£o**

Para o desenvolvimento dos modelos de predi√ß√£o do √≠ndice Dst, adotamos uma abordagem baseada em Redes Neurais Recorrentes (RNN) e Transformers, ambas t√©cnicas avan√ßadas e adequadas para modelagem de s√©ries temporais. Como estamos lidando com dados temporais relacionados √† atividade geomagn√©tica, essas arquiteturas s√£o particularmente eficazes para capturar a din√¢mica complexa das tempestades geomagn√©ticas, divididas em tr√™s fases: in√≠cio, pico, e recupera√ß√£o.

As RNNs (Redes Neurais Recorrentes) s√£o utilizadas para capturar as depend√™ncias temporais entre os eventos passados e presentes. Essa capacidade de "mem√≥ria" permite que a rede aprenda padr√µes recorrentes nos dados de vento solar e atividade solar que influenciam o √≠ndice Dst ao longo do tempo.

O modelo de Transformer, por sua vez, supera algumas limita√ß√µes das RNNs, como a dificuldade de capturar rela√ß√µes de longo prazo. Ele utiliza mecanismos de aten√ß√£o, que identificam de forma mais eficiente quais partes da s√©rie temporal s√£o mais relevantes para a predi√ß√£o em cada ponto. Isso √© particularmente √∫til na modelagem de s√©ries temporais complexas, onde o comportamento das vari√°veis pode mudar de forma imprevis√≠vel entre as fases da tempestade.

## 3.1 - Processamento e Arquitetura do Modelo RNN

O modelo RNN implementado neste projeto tem como objetivo prever o √≠ndice Dst a partir de dados relacionados ao vento solar. A arquitetura da rede neural √© projetada para capturar padr√µes complexos nas s√©ries temporais dos dados, utilizando uma s√©rie de camadas densas com fun√ß√µes de ativa√ß√£o e regulariza√ß√£o.

Os dados de solar_wind e labels s√£o carregados e mesclados com base nas colunas period e timedelta. As caracter√≠sticas relevantes (features) incluem colunas como bt, temperature, bx_gse, by_gse, entre outras, enquanto o alvo (target) √© o √≠ndice dst. A normaliza√ß√£o √© aplicada aos dados de entrada usando o StandardScaler, o qual √© uma t√©cnica de normaliza√ß√£o de dados utilizada no pr√©-processamento, onde transforma as caracter√≠sticas (features) de um conjunto de dados para que tenham m√©dia zero e desvio padr√£o um, garantindo que todos os recursos estejam na mesma escala. O c√°lculo da normaliza√ß√£o desse √© feito com cada dado subtraido da m√©dia de cada feature e dividindo pelo desvio padr√£o.

Tendo em vista a arquitetura do nosso RNN, esse modelo √© constru√≠do utilizando a biblioteca TensorFlow e consiste em v√°rias camadas densas, a primeira camada densa cont√©m 512 neur√¥nios com fun√ß√£o de ativa√ß√£o ReLU e inclui regulariza√ß√£o L2 para evitar overfitting, penalizando pesos grandes durante o treinamento, ao restringir a magnitude dos pesos, a regulariza√ß√£o ajuda a generalizar melhor em novos dados. As camadas intermedi√°rias Dense (256, 128, e 64 neur√¥nios) (camadas adicionais) usam a fun√ß√£o de ativa√ß√£o ReLU e seguem o mesmo padr√£o de regulariza√ß√£o, elas ajudam a aprofundar a rede, permitindo que o modelo capture intera√ß√µes mais sutis entre as caracter√≠sticas, o aumento e a diminui√ß√£o no n√∫mero de neur√¥nios tamb√©m ajudam a criar um "funil", for√ßando a rede a extrair informa√ß√µes mais importantes √† medida que avan√ßa nas camadas. As camadas Dropout ignora aleatoriamente 30% dos neur√¥nios durante o treinamento, o que ajuda a reduzir o overfitting, e ao for√ßar a rede a n√£o depender de neur√¥nios espec√≠ficos ela se torna mais robusta e capaz de generalizar melhor em dados n√£o vistos. A camada final n√£o tem fun√ß√£o de ativa√ß√£o (ou pode ser uma fun√ß√£o de ativa√ß√£o linear, dependendo do contexto), ela produz um √∫nico valor que representa a previs√£o do √≠ndice Dst.

O modelo √© compilado utilizando o otimizador Nadam com uma taxa de aprendizado de 0.0001 e a fun√ß√£o de perda mean squared error (RMSE), adequada para problemas. Os dados s√£o divididos em conjuntos de treinamento e teste, com 80% dos dados utilizados para treinamento e 20% para teste. O treinamento do modelo √© realizado por 100 √©pocas, utilizando um conjunto de valida√ß√£o que representa 20% dos dados de treinamento. O treinamento √© interrompido antecipadamente se a perda de valida√ß√£o n√£o melhorar por 10 √©pocas consecutivas. Durante o treinamento, a curva de perda √© plotada para visualizar a converg√™ncia do modelo.

![image](https://github.com/user-attachments/assets/51cb630d-9409-4607-b41f-644e71e6e508)


Ap√≥s o treinamento, o modelo √© avaliado utilizando o conjunto de teste. O erro quadr√°tico m√©dio (RMSE) √© calculado para quantificar a precis√£o das previs√µes. Um gr√°fico adicional compara os valores reais e preditos, permitindo uma visualiza√ß√£o clara da efic√°cia do modelo na predi√ß√£o do √≠ndice Dst.

![image](https://github.com/user-attachments/assets/d4dbd2df-6115-4414-adb8-65467c2682ae)



## 3.2 - Processamento e Arquitetura do Modelo Transformer

O Transformer para s√©ries temporais funciona capturando padr√µes e depend√™ncias em longas sequ√™ncias de dados temporais. Ele usa mecanismos de autoaten√ß√£o, que permitem que o modelo identifique quais partes de uma sequ√™ncia s√£o mais importantes para prever o pr√≥ximo valor, independentemente da dist√¢ncia temporal. Diferente de RNNs, ele processa todos os pontos de uma sequ√™ncia simultaneamente, o que torna o treinamento mais eficiente e ajuda a capturar rela√ß√µes complexas. A estrutura inclui camadas de codifica√ß√£o que transformam os dados de entrada em representa√ß√µes mais abstratas e √∫teis para a predi√ß√£o.

O modelo Transformer √© um modelo originalmente utilizado para problemas de linguagens naturais, o modelo que estamos utilizando segue uma arquitetura bem estabelecida, mas adaptada para o contexto da predi√ß√£o de s√©ries temporais do √≠ndice Dst. A base do modelo envolve a cria√ß√£o de sequ√™ncias de dados hist√≥ricos para fornecer contexto ao Transformer, que consegue capturar padr√µes temporais e depend√™ncias de longo prazo nos dados.

Ap√≥s o pr√©-processamento, criamos sequ√™ncias de dados, onde cada sequ√™ncia inclui um conjunto de 60 observa√ß√µes temporais consecutivas, que servem como base para o modelo prever o √≠ndice Dst do pr√≥ximo per√≠odo (dst incluso a cada 60 linhas). Essas sequ√™ncias ajudam o Transformer a aprender sobre a evolu√ß√£o dos padr√µes temporais ao longo do tempo. 

O modelo Transformer foi projetado com v√°rias camadas espec√≠ficas. Ele come√ßa com uma camada de proje√ß√£o linear que ajusta a dimens√£o de entrada para o tamanho do modelo (d_model), seguida por um bloco Transformer que inclui camadas de autoaten√ß√£o multi-cabe√ßa (nhead=4), e camadas feedforward para capturar intera√ß√µes n√£o-lineares nos dados. Utilizamos duas camadas codificadoras (num_encoder_layers=2) para garantir que o modelo capture tanto depend√™ncias curtas quanto longas nas sequ√™ncias temporais, e um fator de regulariza√ß√£o (dropout=0.3) para evitar o sobreajuste.

O treinamento do modelo ocorre com o uso de um otimizador Adam e uma fun√ß√£o de perda de erro quadr√°tico m√©dio (MSE), que mede a diferen√ßa entre os valores preditos e os valores reais do √≠ndice Dst. Durante o treinamento, aplicamos early stopping, uma t√©cnica que interrompe o treinamento se a perda de valida√ß√£o n√£o melhorar por v√°rias √©pocas consecutivas, evitando que o modelo aprenda ru√≠dos indesejados nos dados. Avaliamos o desempenho do modelo com base no erro m√©dio quadr√°tico da raiz (RMSE), que fornece uma m√©trica de f√°cil interpreta√ß√£o para analisar a qualidade das previs√µes em rela√ß√£o aos dados reais, por√©m antes de entrar na fun√ß√£o de erro, √© passado uma normaliza√ß√£o usando a fun√ß√£o de sigmoide para evitar erros na avalia√ß√£o.

# 4. **An√°lise de Resultados**

## 4.1 - Resultado RNN
![image](https://github.com/user-attachments/assets/cb78d96a-127e-4e05-915b-a1d78ac1cf9a)

## 4.2 - Resultados Transformer
![image](https://github.com/user-attachments/assets/f0e2fe7c-74be-4f08-868e-5dde77d0b42a)


# 5. **Conclus√£o**

Ao longo deste projeto, aprendemos diversas li√ß√µes valiosas sobre o desenvolvimento de modelos preditivos utilizando redes neurais, especialmente em cen√°rios complexos como a previs√£o de tempestades geomagn√©ticas atrav√©s do √≠ndice Dst. Um dos principais desafios enfrentados foi o tratamento e a prepara√ß√£o dos dados, o que refor√ßou a import√¢ncia do pr√©-processamento rigoroso para garantir a qualidade das previs√µes. A normaliza√ß√£o e a interpola√ß√£o de dados ausentes se mostraram fundamentais para lidar com a natureza heterog√™nea dos dados coletados do vento solar e de outros fen√¥menos relacionados ao clima espacial.

A escolha do modelo, com foco em arquiteturas avan√ßadas como RNN e Transformer, tamb√©m foi um aprendizado importante. Cada um desses modelos trouxe vantagens espec√≠ficas para a modelagem de s√©ries temporais, permitindo capturar din√¢micas temporais complexas e, ao mesmo tempo, controlar o overfitting atrav√©s de regulariza√ß√£o e camadas de dropout (eventos extremos). A m√©trica RMSE nos permitiu avaliar de forma clara e objetiva o desempenho dos modelos, fornecendo uma base s√≥lida para comparar resultados e ajustar a arquitetura e os hiperpar√¢metros do modelo conforme necess√°rio.

Em termos pr√°ticos, os modelos desenvolvidos t√™m o potencial de serem aplicados em sistemas de monitoramento e previs√£o de tempestades geomagn√©ticas, auxiliando na prote√ß√£o de infraestruturas tecnol√≥gicas sens√≠veis a dist√∫rbios no campo magn√©tico da Terra. Como pr√≥ximos passos, seria interessante explorar a implementa√ß√£o de pipelines de aprendizado cont√≠nuo, permitindo que os modelos se adaptem em tempo real √†s mudan√ßas nas condi√ß√µes do vento solar, tornando o sistema mais robusto e eficaz para aplica√ß√µes pr√°ticas


Obrigado
üëã ü§ñ
